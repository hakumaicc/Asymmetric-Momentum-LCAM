{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420682d9",
   "metadata": {},
   "source": [
    "# Draw with plt (NOT Tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd93c90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ea1=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.9-*0.2_30_60_90/')\n",
    "ea2=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.95-*0.2_30_60_90/')\n",
    "ea3=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.95_0.9-*0.2_30_60_90/')\n",
    "ea4=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.9_0.95-*0.2_30_60_90/')\n",
    "\n",
    "ea5=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.9-30*0.99985/')\n",
    "ea6=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.9_0.95-30*0.99985/')\n",
    "\n",
    "ea7=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.9-*0.2_30_60_90/')\n",
    "ea8=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.95-*0.2_30_60_90/')\n",
    "ea9=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.95_0.9-*0.2_30_60_90/')\n",
    "ea10=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.9_0.95-*0.2_30_60_90/')\n",
    "\n",
    "ea11=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.9-30*0.99985/')\n",
    "ea12=event_accumulator.EventAccumulator('./runs/Cifar100-0.1-m0.93_0.9-30*0.99985/')\n",
    "\n",
    "ea1.Reload()\n",
    "ea2.Reload()\n",
    "ea3.Reload()\n",
    "ea4.Reload()\n",
    "ea5.Reload()\n",
    "ea6.Reload()\n",
    "ea7.Reload()\n",
    "ea8.Reload()\n",
    "ea9.Reload()\n",
    "ea10.Reload()\n",
    "ea11.Reload()\n",
    "ea12.Reload()\n",
    "\n",
    "x=[]\n",
    "\n",
    "y1=[]\n",
    "y1a=[]\n",
    "y2=[]\n",
    "y2a=[]\n",
    "y3=[]\n",
    "y3a=[]\n",
    "y4=[]\n",
    "y4a=[]\n",
    "\n",
    "y5=[]\n",
    "y6=[]\n",
    "\n",
    "y7=[]\n",
    "y7a=[]\n",
    "y8=[]\n",
    "y8a=[]\n",
    "y9=[]\n",
    "y9a=[]\n",
    "y10=[]\n",
    "y10a=[]\n",
    "\n",
    "y11=[]\n",
    "y12=[]\n",
    "\n",
    "#1#Cifar10-0.1-m0.9-*0.2_30_60_90\n",
    "\n",
    "val_psnr=ea1.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    x.append(i.step)\n",
    "for i in val_psnr:\n",
    "    y1.append(i.value)\n",
    "val_psnr=ea1.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y1a.append(i.value)\n",
    "    \n",
    "#2#Cifar10-0.1-m0.95-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea2.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y2.append(i.value)\n",
    "val_psnr=ea2.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y2a.append(i.value)\n",
    "    \n",
    "#3#Cifar10-0.1-m0.95_0.9-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea3.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y3.append(i.value)\n",
    "val_psnr=ea3.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y3a.append(i.value)\n",
    "    \n",
    "#4#Cifar10-0.1-m0.9_0.95-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea4.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y4.append(i.value)\n",
    "val_psnr=ea4.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y4a.append(i.value)\n",
    "    \n",
    "#5#Cifar10-0.1-m0.9-30*0.99985\n",
    "val_psnr=ea5.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y5.append(i.value)\n",
    "\n",
    "#6#Cifar10-0.1-m0.9_0.95-30*0.99985\n",
    "val_psnr=ea6.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y6.append(i.value)\n",
    "    \n",
    "\n",
    "    \n",
    "#7#Cifar100-0.1-m0.9-*0.2_30_60_90\n",
    "\n",
    "val_psnr=ea7.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y7.append(i.value)\n",
    "val_psnr=ea7.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y7a.append(i.value)\n",
    "    \n",
    "#8#Cifar100-0.1-m0.95-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea8.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y8.append(i.value)\n",
    "val_psnr=ea8.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y8a.append(i.value)\n",
    "    \n",
    "#9#Cifar100-0.1-m0.95_0.9-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea9.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y9.append(i.value)\n",
    "val_psnr=ea9.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y9a.append(i.value)\n",
    "    \n",
    "#10#Cifar100-0.1-m0.9_0.95-*0.2_30_60_90\n",
    "    \n",
    "val_psnr=ea10.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y10.append(i.value)\n",
    "val_psnr=ea10.scalars.Items('TrainLoss / Epoch')\n",
    "for i in val_psnr:\n",
    "    y10a.append(i.value)\n",
    "    \n",
    "#11#Cifar100-0.1-m0.9-30*0.99985\n",
    "val_psnr=ea11.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y11.append(i.value)\n",
    "\n",
    "#12#Cifar100-0.1-m0.93_0.9-30*0.99985\n",
    "val_psnr=ea12.scalars.Items('TestError / Epoch')\n",
    "for i in val_psnr:\n",
    "    y12.append(i.value)\n",
    "    \n",
    "plt.figure()    \n",
    "plt.xlim(60,150)\n",
    "plt.ylim(3.8,7)\n",
    "plt.plot(x, y1, label='1', color='black')\n",
    "plt.plot(x, y2, label='2', color='blue')\n",
    "plt.plot(x, y3, label='3', color='red')\n",
    "plt.plot(x, y4, label='4', color='green')\n",
    "plt.title('Figure.3 Test Error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()    \n",
    "plt.xlim(60,150)\n",
    "plt.ylim(1e-3,1e-1)\n",
    "plt.semilogy(x, y1a, label='1a', color='black')\n",
    "plt.semilogy(x, y2a, label='2a', color='blue')\n",
    "plt.semilogy(x, y3a, label='3a', color='red')\n",
    "plt.semilogy(x, y4a, label='4a', color='green')\n",
    "plt.title('Figure.3 Average Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()    \n",
    "plt.xlim(30,150)\n",
    "plt.ylim(19,50)\n",
    "plt.plot(x, y7, label='7', color='black')\n",
    "plt.plot(x, y8, label='8', color='blue')\n",
    "plt.plot(x, y9, label='9', color='red')\n",
    "plt.plot(x, y10, label='10', color='green')\n",
    "plt.title('Figure.4 Test Error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()    \n",
    "plt.xlim(30,150)\n",
    "plt.ylim(2e-3,2e-0)\n",
    "plt.semilogy(x, y7a, label='7a', color='black')\n",
    "plt.semilogy(x, y8a, label='8a', color='blue')\n",
    "plt.semilogy(x, y9a, label='9a', color='red')\n",
    "plt.semilogy(x, y10a, label='10a', color='green')\n",
    "plt.title('Figure.4 Average Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()    \n",
    "plt.xlim(60,150)\n",
    "plt.ylim(3.8,7)\n",
    "plt.plot(x, y5, label='5', color='black')\n",
    "plt.plot(x, y6, label='6', color='green')\n",
    "plt.title('Figure.5 Cifar10 Test Error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()    \n",
    "plt.xlim(60,150)\n",
    "plt.ylim(19,24)\n",
    "plt.plot(x, y11, label='11', color='black')\n",
    "plt.plot(x, y12, label='12', color='green')\n",
    "plt.title('Figure.5 Cifar100 Test Error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57f93a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Start Tensorboard Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be39cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#%tensorboard --logdir=./runs/ \n",
    "%tensorboard --logdir=./runs/ --port=6006\n",
    "#%tensorboard --logdir=./runs/ --reuse_port=True\n",
    "#%tensorboard --logdir=./runs/ --reuse_port=False\n",
    "#%tensorboard --logdir=./runs/ --reuse_port=True --port=6006\n",
    "#%tensorboard --logdir=./runs/ --reuse_port=False --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f788e",
   "metadata": {},
   "source": [
    "# Extract Data Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475859c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    " \n",
    "#加载日志数据\n",
    "ea=event_accumulator.EventAccumulator('./runs/Cifar10-0.1-m0.9-30*0.99985/') \n",
    "ea.Reload()\n",
    "print(ea.scalars.Keys())\n",
    " \n",
    "val_psnr=ea.scalars.Items('TestError / Epoch')\n",
    "print(len(val_psnr))\n",
    "for i in val_psnr:\n",
    "    print((i.step,i.value), end='')\n",
    "\n",
    "print()\n",
    "\n",
    "val_psnr=ea.scalars.Items('TrainLoss / Epoch')\n",
    "print(len(val_psnr))\n",
    "for i in val_psnr:\n",
    "    print((i.step,i.value), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a21fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
